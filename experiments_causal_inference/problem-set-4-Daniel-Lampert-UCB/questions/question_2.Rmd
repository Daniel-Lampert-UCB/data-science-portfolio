# 2. Fun with the placebo

The table below summarizes the data from a political science experiment on voting behavior. Subjects were randomized into three groups: a baseline control group (not contacted by canvassers), a treatment group (canvassers attempted to deliver an encouragement to vote), and a placebo group (canvassers attempted to deliver a message unrelated to voting or politics).

```{r, echo=FALSE}
library(knitr)
summary_table <- data.table(
  'Assignment' = c('Baseline', 'Treatment', 'Treatment', 'Placebo', 'Placebo'), 
  'Treated?'   = c('No', 'Yes', 'No', 'Yes', 'No'), 
  'N'          = c(2463, 512, 1898, 476, 2108), 
  'Turnout'    = c(.3008, .3890, .3160, .3002, .3145)
)

kable(summary_table)
``` 

## Evaluating the Placebo Group

1. Construct a data set that would reproduce the table. (Too frequently we receive data that has been summarized up to a level that is unuseful for our analysis. Here, we're asking you to "un-summarize" the data to conduct the rest of the analysis for this question.)

```{r construct placebo data}
nrow <- sum(summary_table$N)
d <- data.table(
  id = 1:sum(summary_table$N)
)
d[1:2463, `:=` (assignment = 'Baseline', treated = 0, turnout = c(rep(0, 1723), rep(1, 740)))]
d[2464: sum(2463, 512), `:=` (assignment = 'Treatment', treated = 1, turnout = c(rep(0, 313), rep(1, 199)))]
d[2976: sum(2463, 512, 1898), `:=` (assignment = 'Treatment', treated = 0, turnout = c(rep(0, 1298), rep(1, 600)))]
d[4873 : sum(2463, 512, 1898, 476), `:=` (assignment = 'Placebo', treated = 1, turnout = c(rep(0, 334), rep(1, 143)))]
d[sum(2463, 512, 1898, 476, 1):.N, `:=` (assignment = 'Placebo', treated = 0, turnout = c(rep(0, 1445), rep(1, 663)))]



```



2. Estimate the proportion of compliers by using the data on the treatment group.

```{r treatment group compliance rate}
complier <- d[assignment == 'Treatment' & treated == 1, .N]
total <- d[assignment == 'Treatment', .N]
compliance_rate_t <- complier/total

compliance_rate_t

```

3. Estimate the proportion of compliers by using the data on the placebo group.

```{r placebo group compliance rate}
compliance_rate_p <- d[assignment == 'Placebo' & treated == 1, .N]/d[assignment == 'Placebo', .N]
compliance_rate_p
```

4. Are the proportions in parts (1) and (2) statistically significantly different from each other? Provide *a test* and n description about why you chose that particular test, and why you chose that particular set of data. 

```{r proportions difference}
proportions_difference_test <- prop.test(
  x = c(d[assignment == 'Treatment' & treated == 1, .N], d[assignment == 'Placebo' & treated == 1, .N]),
  n = c(d[assignment == 'Treatment', .N], d[assignment == 'Placebo', .N]))
  
proportions_difference_test
```

> I decided to use a Z-test since the number of people is sufficiently large for the central limit to stand. For this reason a Z test is appropriate. I choose the subset of the data that was used in the calculation of the proportion. The x variable in the test is the number of people who complied and n is the total number of people. In this case, the results from a Z-test and a T-test should be very similar since the number of individuals is large.

5. What critical assumption does this comparison of the two groups' compliance rates test? Given what you learn from the test, how do you suggest moving forward with the analysis for this problem? 

> This tests the assumption that the rate of non-compliance does not vary accross groups. This test shows that non-compliance in fact does vary accross groups. Going forward, I would want to check and see if there were any particular causes which led to non-compliance accross groups. 

6. Estimate the CACE of receiving the placebo. Is the estimate consistent with the assumption that the placebo has no effect on turnout?

```{r cace of placebo}
itt <- (d[assignment == "Placebo" & turnout == 1, .N]/d[assignment == "Placebo", .N]) - (d[assignment == "Baseline" & turnout == 1, .N]/d[assignment == "Baseline", .N])
itt_d <- (d[assignment == "Placebo" & treated == 1, .N]/d[assignment == "Placebo", .N])
cace_estimate <- itt/itt_d


cace_estimate <- ((d[assignment == "Placebo", mean(turnout)])-(d[assignment == "Baseline", mean(turnout)]))/(d[assignment == "Placebo" & treated == 1, .N]/d[assignment == "Placebo", .N])
cace_estimate
```

> No it seems like there actually is **somewhat of an effect**. If there were no effect we'd espect the estimate to be closer to 0. A p-value, a standard error and or a confidence interval would improve the ability to reason if this is a real effect. 

## Estimate the CACE Several Ways

7. Using a difference in means (i.e. not a linear model), compute the ITT using the appropriate groups' data. Then, divide this ITT by the appropriate compliance rate to produce an estiamte the CACE.  

```{r cace through means }
itt <- ((d[assignment == "Treatment", mean(turnout)])-(d[assignment == "Baseline", mean(turnout)]))
cace_means <- itt/(d[assignment == "Treatment", mean(treated)])
cace_means
```

8. Use two separate linear models to estimate the CACE of receiving the treatment by first estimating the ITT and then dividing by $ITT_{D}$. Use the `coef()` extractor and in line code evaluation to write a descriptive statement about what you learn after your code. 

```{r itt / d}
itt_model <- d[assignment == 'Treatment'|assignment == 'Baseline', lm(turnout ~ assignment)]
itt_d_model <- d[, lm(treated ~ assignment)]
cace_model_estimate <- coef(itt_model)[2]/coef(itt_d_model)[3] #check why 3 not 2
cace_model_estimate

```
> Not surprisignly this gives identical results to the ITT computed above. The `cace_model_estimate` shows the causal effect of treatment on turnout.

9. When a design uses a placebo group, one additional way to estiamte the CACE is possible -- subset to include only compliers in the treatment and placebo groups, and then estimate a linear model. Produce that estimate here. 

```{r cace subset} 
cace_subset_model <- d[assignment != 'Baseline' & treated == 1, lm(turnout ~ assignment)]
cace_subset_model
```

10. In large samples (i.e. "in expectation") when the design is carried out correctly, we have the expectation that the results from 7, 8, and 9 should be the same. Are they? If so, does this give you confidence that these methods are working well. If not, what explains why these estimators are producing different estimates? 

> The results for 7 and 8 are the same but the results for 9 are not. I think the method in 9 is giving a different result because it is utilizing the placebo set rather than the baseline. In this case there were some differences between the placebo group and the baseline that should not be there. The **difference** in the compliance rate between the placebo group and the treatment group is the source of the issue.

11. In class we discussed that the rate of compliance determines whether one or another design is more efficient. (You can review the textbook expectation on page 162 of _Field Experiments_)). Given the compliance rate in this study, which design *should* provide a more efficient estimate of the treatment effect?

> Since the compliance ratio or ITT_d is less than 50% the placebo design is more efficient for the study.

12. When you apply what you've said in part (11) against the data that you are working with, does the {placebo vs. treatment} or the {control vs. treatment} comparison produce an estimate with smaller standard errors? 
```{r}
#for baseline vs treatment
itt_model$vcovCL_val <- vcovCL(itt_model)
itt_model_test <- coeftest(x = itt_model, level = 0.95, vcov. =itt_model$vcovCL_val)
#itt_model_test
#itt_model_test[2,2]/coef(itt_d_model)[3] # pulls the SE 

#for placebo vs treatment
cace_subset_model$vcovCL_val <- vcovCL(cace_subset_model)
cace_subset_model_test <- coeftest(x = cace_subset_model, level = 0.95, vcov. = cace_subset_model$vcovCL_val)
#cace_subset_model_test[2,2]

```


> The placebo vs treatment should produce smaller standard errors. The placebo design improves efficiency of the estimate thus narrowing the standard errors. However, in this case the SE is actually higher for the placebo group due to non-compliance. To show this, this is the standard error for the baseline vs treatment `r  itt_model_test[2,2]/coef(itt_d_model)[3]` vs placebo vs treament `r cace_subset_model_test[2,2]`.






