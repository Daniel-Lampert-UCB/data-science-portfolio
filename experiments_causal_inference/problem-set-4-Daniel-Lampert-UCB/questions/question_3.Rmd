# 3. Turnout in Dorms

Guan and Green report the results of a canvassing experiment conduced in Beijing on the eve of a local election. Students on the campus of Peking University were randomly assigned to treatment or control groups. 

- Canvassers attempted to contact students in their dorm rooms and encourage them to vote. 
- No contact with the control group was attempted. 
- Of the 2,688 students assigned to the treatment group, 2,380 were contacted. 
- A total of 2,152 students in the treatment group voted; of the 1,334 students assigned to the control group, 892 voted. 
- One aspect of this experiment threatens to violate the exclusion restriction. At every dorm room they visited, even those where no one answered, canvassers left a leaflet encouraging students to vote. 

```{r read dorm data}
library(sandwich)
library(lmtest)
library(data.table)
d <- fread('https://ucb-mids-w241.s3-us-west-1.amazonaws.com/Guan_Green_CPS_2006.csv')
d
```

Here are definitions for what is in that data: 

- `turnout` did the person turn out to vote?
- `treated` did someone at the dorm open the door? 
- `dormid` a unique ID for the door of the dorm
- `treatment_group` whether the dorm door was assigned to be treated or not

## Use Linear Regressions 

1. Estimate the ITT using a linear regression on the appropriate subset of data. Notice that there are two `NA` in the data. Just na.omit to remove these rows so that we are all working with the same data. Given the ways that randomization was conducted, what is the appropriate way to construct the standard errors? 

```{r dorm itt}

#dont think a subset is neccessary since no placebo group, need clustered standard errors for dorm
d <- na.omit(d)
dorm_model <- d[, lm(turnout ~ treatment_group)]
dorm_model$vcovCL_val <- vcovCL(dorm_model, cluster = d[,dormid])
dorm_model_test <- coeftest(x = dorm_model, level = 0.95, vcov. = dorm_model$vcovCL_val)
dorm_model_conf <- coefci(x = dorm_model, level = 0.95, vcov. = dorm_model$vcovCL_val)
dorm_model_test
dorm_model_conf
```
> I used robust clustered standard errors since the experiment was conducted at the dorm level rather than the individual level.

## Use Randomization Inference  

1. How many people are in treatment and control? Does this give you insight into how the scientists might have randomized? As ususal, include a narrative setence after your code.   

```{r people in treatment} 
n_treatment <- d[treatment_group ==1, .N]
n_control   <- d[treatment_group == 0, .N]
n_treatment
n_control
```
> There are 2688 people in the treatment group and 1334 in control. This gives some limitted insight into their randomization strategy. I presume that used a probability sample to shuffle people into the control or treatment group. It was most likely intentional to have more people in the treatment group.

2. Write an algorithm to conduct the Randomization Inference. Be sure to take into account the fact that random assignment was clustered by dorm room.

```{r dorm room randomization inference}
#unique_dorms <- d[, unique(dormid)]
#treated_dorms <- length(d[treatment_group == 1, unique(dormid)])

clustered_randomization <- function(data) {
      unique_dorms <- data[, unique(dormid)]
      n_treated_dorms <- length(data[treatment_group ==1, unique(dormid)])
      treated_ids <- sample(x = unique_dorms,
                            size = n_treated_dorms,
                            replace = FALSE)
      return(as.numeric(data[,dormid] %in% treated_ids))
    
}
ri_dist <- replicate(1000, d[, .(turnout_mean = mean(turnout)), 
                             keyby = clustered_randomization(d)]
                     [,diff(turnout_mean)])
```
  
3. What is the value that you estimate for the treatment effect?

```{r dorm room ATE}
dorm_room_ate <- mean(d[treatment_group == 1, turnout]) - mean(d[treatment_group == 0, turnout])
dorm_room_ate
```
> The estimated ATE is `r dorm_room_ate`

4. What are the 2.5% and 97.5% quantiles of this distribution? 

```{r dorm room ri CI}
dorm_room_ci <- quantile(ri_dist, probs = c(0.025, 0.975))
dorm_room_ci
```
> The quantiles range from `r dorm_room_ci` which includes zero. Since zero is included in the range, that means the results are not significant. This makes sense since this distribution was generated under the sharp null.

5. What is the p-value that you generate for the test: How likely is this treatment effect to have been generated if the sharp null hypothesis were true. 
  
```{r dorm room ri p-value}
p_value <- mean(abs(ri_dist) > dorm_room_ate)
p_value
```
> This indicates that the ATE we calculated is highly significant with a zero P-value. This P-value was generated by comparing the ATE against the sharp null hpyothesis. 

6. Assume that the leaflet (which was left in case nobody answered the door) had no effect on turnout. Estimate the CACE either using ITT and ITT_d or using a set of linear models. What is the CACE, the estimated standard error of the CACE, and the p-value of the test you conduct?  
  
```{r dorm room cace}
library("ivreg")
ivyreg <- d[, ivreg(turnout ~ treated |treatment_group)]
ivyreg$vcovCL_val <- vcovCL(ivyreg, cluster = d[,dormid])
ivyreg_test <- coeftest(x = ivyreg, level = 0.95, vcov. = ivyreg$vcovCL_val)
ivyreg_test
```  
> I decided to use instrumental variable by two-stage least squares to greatly facilitate the ease of calculating the standard error and the p-value. The coefficient for the treatment variable is `r ivyreg_test[2,1]`  with a standard error of 0.0263 and a highly significant P-value. 


7. What if the leaflet that was left actually *did* have an effect? Is it possible to estimate a CACE in this case? Why or why not? 

> If the leaflet did have an effect the ITT_d or compliance rate would be nearly impossible to interpret. This would mean that people in the treatment group who did not receive the intended intervention, contact with a convasser, received a partial treatment instead. This would make it nearly impossible to know the effect of contact with a convasser. This would lead to an odd middle ground where non-compliers essentially received a partial treatment. For this reason I think the CACE would be a misleading statistic. This would lead to a bias in the CACE where its effect is overestimated.





