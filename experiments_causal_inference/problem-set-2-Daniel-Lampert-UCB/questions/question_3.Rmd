# 3. Sports Cards

In this experiment, the experimenters invited consumers at a sports card trading show to bid against one other bidder for a pair trading cards.  We abstract from the multi-unit-auction details here, and simply state that the treatment auction format was theoretically predicted to produce lower bids than the control auction format.  We provide you a relevant subset of data from the experiment.

In this question, we are asking you to produce p-values and confidence intervals in three different ways: 

1. Using a `t.test`; 
2. Using a regression; and,
3. Using randomization inference. 

```{r load cards data }
library(data.table)
d <- fread('../data/list_data_2019.csv')
```

1. Using a `t.test`, compute a 95% confidence interval for the difference between the treatment mean and the control mean. After you conduct your test, write a narrative statement, using inline code evaluation that describes what your tests find, and how you interpret these results. (You should be able to look into `str(t_test_cards)` to find the pieces that you want to pull to include in your written results.) 

```{r cards t-test}
t_test_cards <- t.test(bid ~uniform_price_auction, d)# this should be the t.test object. Extract pieces from this object in-text below the code chunk. 
t_test_cards$conf.int
#t_test_cards <- t.test(x = d[uniform_price_auction == 1, bid], y = d[uniform_price_auction == 0, bid])
#t_test_cards
```
> The confidence interval is from 11.9334 to 12.478. Since 0 is not contained in the interval, therefore there is significant evidence to reject the null hypothesis.

2. In plain language, what does this confidence interval mean? 

> For a t test, the confidence interval is the probability that the mean will fall between a given set of values for a certain percentage of the time. In this test, the mean will fall between 11.9334 to 12.478 95% of the time with repeated experimentation.

3. Conduct a randomization inference process using an estimator that you write by hand (i.e. in the same way as earlier questions). On the sharp-null distribution that this process creates, compute the 2.5% quantile and the 97.5% quantile using the function `quantile` with the appropriate vector passed to the `probs` argument. After you conduct your test, write a narrative statement of your test results. 

```{r cards randomization inference} 
## first, do you work for the randomization inference
randomize <- function(len_control, len_tretment) {
  return(sample(c(rep(0,len_control), rep(1, len_tretment))))
}


ate <- function(data) {
  data[, con := randomize(.N-sum(uniform_price_auction), sum(uniform_price_auction))]
  res <- data[, .(mean_b = mean(bid)), keyby = con]
  return(res[con == 1, mean_b]- res[con == 0, mean_b])
}

#ate(d)
ri_distribution <- replicate(10000, ate(d)) # numeric vector of length equal to your number of RI permutations
ri_quantiles    <- quantile(ri_distribution, probs = c(0.025, 0.975)) # there's a built-in to pull these. 
ri_quantiles
```
> The 95% confidence interval extends from -8.852941 to 9.088235 which contains 0. This means that the results are not statistically significant and thus, we fail to reject the null. In practical terms, this means that the value falls somewhere in that range 95% of the time.

4. Do you learn anything different if you regress the outcome on a binary treatment variable? To answer this question, regress `bid` on a binary variable equal to 0 for the control auction and 1 for the treatment auction and then calculate the 95% confidence interval using *classical standard errors* (in a moment you will calculate with *robust standard errors*). There are two ways to do this -- you can code them by hand; or use a built-in, `confint`. After you conduct your test, write a narrative statement of your test results. 

```{r cards ols regression}
mod <- lm(bid ~ uniform_price_auction, data = d) # this should be a model object, class = 'lm'. 
confint(mod)
```
> Using regression with classical standard errors we get a confidence interval from 20.844 to -3.5676. Since zero is not contained, there is sufficient evidence to reject the null hypothesis.

5. Calculate the 95% confidence interval using robust standard errors, using the `sandwich` package. There is a function in `lmtest` called `coefci` that can help with this. It is also possible to do this work by hand. After you conduct your test, write a narrative statement of your test results.

```{r cards robust ci}
library(sandwich)
lmtest::coefci(mod, vcov = vcovHC(mod, type ="HC"), "uniform_price_auction")
```
> The results for the robust standard errors are also significant as zero is not contained. They range from -20.716 to 3.6955. Using robust standard erros means that they are more reliable under heteroskedacity. 

6. Characterize what you learn from each of these different methods -- are the results contingent on the method of analysis that you choose? 
> I was surprised that the results from randomization inference were so different from the t-test and regression. Both regression and the t-test produced significant results whereas randomization inference did not. 
